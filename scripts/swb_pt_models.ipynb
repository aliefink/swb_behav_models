{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWB Prospect Theory Modeling\n",
    "\n",
    "\n",
    "Created: 06/20/2023 by Alie Fink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize # minimize function is used for parameter recovery \n",
    "import seaborn as sns \n",
    "import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/swb_computational_modeling/swb_behav_models/scripts/')\n",
    "import SWB_modeling_utils "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Optim Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "swb_dir = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/'\n",
    "subj_list = pd.read_excel(f'{swb_dir}SWB_subjects.xlsx', sheet_name='Usable_Subjects', usecols=[0])\n",
    "subj_ids = list(subj_list.PatientID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DA8',\n",
       " 'DA9',\n",
       " 'DA10',\n",
       " 'DA11',\n",
       " 'DA023',\n",
       " 'MS002',\n",
       " 'MS003',\n",
       " 'MS016',\n",
       " 'MS017',\n",
       " 'MS019',\n",
       " 'MS022',\n",
       " 'MS025',\n",
       " 'MS026',\n",
       " 'MS027',\n",
       " 'MS029',\n",
       " 'MS030']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_path = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/swb_computational_modeling/swb_behav_models/data/model_input_data_06192023'\n",
    "model_input = pd.read_csv(model_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>round</th>\n",
       "      <th>rate</th>\n",
       "      <th>zscore_rate</th>\n",
       "      <th>cr(t-1)</th>\n",
       "      <th>cr(t-2)</th>\n",
       "      <th>cr(t-3)</th>\n",
       "      <th>choice_ev(t-1)</th>\n",
       "      <th>choice_ev(t-2)</th>\n",
       "      <th>choice_ev(t-3)</th>\n",
       "      <th>...</th>\n",
       "      <th>totalregret(t-3)</th>\n",
       "      <th>decisionregret(t-1)</th>\n",
       "      <th>decisionregret(t-2)</th>\n",
       "      <th>decisionregret(t-3)</th>\n",
       "      <th>totalrelief(t-1)</th>\n",
       "      <th>totalrelief(t-2)</th>\n",
       "      <th>totalrelief(t-3)</th>\n",
       "      <th>decisionrelief(t-1)</th>\n",
       "      <th>decisionrelief(t-2)</th>\n",
       "      <th>decisionrelief(t-3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DA8</td>\n",
       "      <td>4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-1.156527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DA8</td>\n",
       "      <td>7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.054333</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DA8</td>\n",
       "      <td>10</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.861574</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DA8</td>\n",
       "      <td>13</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.668814</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA8</td>\n",
       "      <td>16</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.870624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>MS030</td>\n",
       "      <td>139</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>MS030</td>\n",
       "      <td>142</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-0.372999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>MS030</td>\n",
       "      <td>145</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-0.372999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>MS030</td>\n",
       "      <td>148</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>MS030</td>\n",
       "      <td>151</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-0.372999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subj_id  round  rate  zscore_rate  cr(t-1)  cr(t-2)  cr(t-3)  \\\n",
       "0       DA8      4  74.0    -1.156527      0.0      0.0      0.0   \n",
       "1       DA8      7  80.0     0.054333     -0.3     -0.3      0.0   \n",
       "2       DA8     10  84.0     0.861574      0.6      0.6      0.0   \n",
       "3       DA8     13  88.0     1.668814     -0.5     -0.5      0.0   \n",
       "4       DA8     16  89.0     1.870624      0.0      0.0     -0.5   \n",
       "..      ...    ...   ...          ...      ...      ...      ...   \n",
       "795   MS030    139  47.0     0.261100      0.0      0.0      0.0   \n",
       "796   MS030    142  46.0    -0.372999      0.0      0.0      0.0   \n",
       "797   MS030    145  46.0    -0.372999      0.0      0.0      0.0   \n",
       "798   MS030    148  47.0     0.261100      0.0      0.0      0.0   \n",
       "799   MS030    151  46.0    -0.372999      0.0      0.0      0.0   \n",
       "\n",
       "     choice_ev(t-1)  choice_ev(t-2)  choice_ev(t-3)  ...  totalregret(t-3)  \\\n",
       "0              0.00            0.03           0.000  ...              0.00   \n",
       "1              0.00            0.00           0.315  ...              0.00   \n",
       "2              0.00            0.50           0.000  ...              0.00   \n",
       "3              0.00            1.50           0.000  ...             -0.16   \n",
       "4              0.00            0.00           0.000  ...              0.00   \n",
       "..              ...             ...             ...  ...               ...   \n",
       "795            0.56           -0.56           0.000  ...              0.00   \n",
       "796           -0.79            0.00           0.000  ...              0.00   \n",
       "797           -0.42            0.00           0.000  ...             -0.41   \n",
       "798           -0.42            0.90           0.315  ...              0.00   \n",
       "799           -0.18           -0.72          -0.665  ...             -1.33   \n",
       "\n",
       "     decisionregret(t-1)  decisionregret(t-2)  decisionregret(t-3)  \\\n",
       "0                  -1.50                 0.00                 0.00   \n",
       "1                  -0.30                 0.00                 0.00   \n",
       "2                   0.00                 0.00                 0.00   \n",
       "3                  -0.50                 0.00                -0.16   \n",
       "4                   0.00                 0.00                 0.00   \n",
       "..                   ...                  ...                  ...   \n",
       "795                -0.40                -0.72                 0.00   \n",
       "796                -1.08                 0.00                 0.00   \n",
       "797                -0.34                 0.00                -0.41   \n",
       "798                -0.54                 0.00                 0.00   \n",
       "799                 0.00                -1.04                -0.73   \n",
       "\n",
       "     totalrelief(t-1)  totalrelief(t-2)  totalrelief(t-3)  \\\n",
       "0                0.00              0.66              0.80   \n",
       "1                0.00              0.30              0.63   \n",
       "2                0.60              1.00              0.80   \n",
       "3                0.00              3.00              0.00   \n",
       "4                0.30              1.08              0.90   \n",
       "..                ...               ...               ...   \n",
       "795              0.00              0.00              1.50   \n",
       "796              0.00              0.80              0.30   \n",
       "797              0.00              0.20              0.00   \n",
       "798              0.00              1.80              0.63   \n",
       "799              0.36              0.00              0.00   \n",
       "\n",
       "     decisionrelief(t-1)  decisionrelief(t-2)  decisionrelief(t-3)  \n",
       "0                    0.0                 0.36                 0.80  \n",
       "1                    0.0                 0.30                 0.43  \n",
       "2                    0.6                 0.80                 0.80  \n",
       "3                    0.0                 2.40                 0.00  \n",
       "4                    0.3                 1.08                 0.90  \n",
       "..                   ...                  ...                  ...  \n",
       "795                  0.0                 0.00                 1.50  \n",
       "796                  0.0                 0.80                 0.30  \n",
       "797                  0.0                 0.20                 0.00  \n",
       "798                  0.0                 1.30                 0.43  \n",
       "799                  0.2                 0.00                 0.00  \n",
       "\n",
       "[800 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Base PT Model\n",
    "- free params: risk aversion, loss aversion, temp\n",
    "- bounds = (0.1,3),(0.1,5),(0.1,20)\n",
    "- beta distrubution assumptions = [1,9],[2,4],[1,8]\n",
    "\n",
    "distribution assumptions estimated from Charpentier et al 2016 DATA_for_JASP_Anxiety.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=3, lower_bound=0.1, method='beta',beta_shape=[1,9])\n",
    "loss_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=4, lower_bound=0.1, method='beta',beta_shape=[2,4])\n",
    "temp_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=20, lower_bound=0.1, method='beta',beta_shape=[1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swb_base_pt_dict = {}\n",
    "bounds=(0.1,3),(0.1,4),(0.1,20)\n",
    "\n",
    "for subj_id in subj_ids:\n",
    "    df = pd.read_csv(f'{swb_dir}behavior_analysis/behavior_preprocessed/{subj_id}_task_data')\n",
    "    risk_est, loss_est, temp_est, bic_est, optim_inits = SWB_modeling_utils.run_base_pt(df,risk_inits,loss_inits,temp_inits,bounds=bounds)\n",
    "    if risk_est == 0:\n",
    "        print(subj_id)\n",
    "    swb_base_pt_dict[subj_id] = {'risk_estimation':risk_est,\n",
    "                                'loss_estimation':loss_est,\n",
    "                                'temp_estimation':temp_est,\n",
    "                                'bic_estimation':bic_est,\n",
    "                                'optim_inits':optim_inits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26361451 0.10668719 0.33909693 0.45696763 0.34206114] [1.45372477 0.75793349 0.57393343 0.37239053 1.79138866] [2.14422819 0.4040581  0.962921   0.50246531 0.188585  ]\n"
     ]
    }
   ],
   "source": [
    "risk_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=3, lower_bound=0.1, method='beta',beta_shape=[1,9])\n",
    "loss_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=4, lower_bound=0.1, method='beta',beta_shape=[2,4])\n",
    "temp_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=20, lower_bound=0.1, method='beta',beta_shape=[1,8])\n",
    "print(risk_inits,loss_inits,temp_inits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_id = 'MS025'\n",
    "# df = pd.read_csv(f'{swb_dir}behavior_analysis/behavior_preprocessed/{subj_id}_task_data')\n",
    "# risk_est, loss_est, temp_est, bic_est, optim_inits = SWB_modeling_utils.run_base_pt(df,risk_inits,loss_inits,temp_inits,bounds=bounds)\n",
    "# print(risk_est,loss_est,bic_est,temp_inits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12405224 0.20046404 0.47409242 0.11141767 0.20446688] [0.91409761 1.88177556 0.2253611  1.42627017 1.10411835] [0.20999594 1.74911005 2.30996617 3.22424843 0.56821895]\n"
     ]
    }
   ],
   "source": [
    "risk_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=3, lower_bound=0.1, method='beta',beta_shape=[1,9])\n",
    "loss_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=4, lower_bound=0.1, method='beta',beta_shape=[2,4])\n",
    "temp_inits = SWB_modeling_utils.param_init(n_values=1, n_iter=5, upper_bound=20, lower_bound=0.1, method='beta',beta_shape=[1,8])\n",
    "print(risk_inits,loss_inits,temp_inits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Trial Num</th>\n",
       "      <th>TrialType</th>\n",
       "      <th>TrialOnset</th>\n",
       "      <th>ChoiceOnset</th>\n",
       "      <th>DecisionOnset</th>\n",
       "      <th>FeedbackOnset</th>\n",
       "      <th>RT</th>\n",
       "      <th>SafeBet</th>\n",
       "      <th>LowBet</th>\n",
       "      <th>...</th>\n",
       "      <th>GambleEV</th>\n",
       "      <th>CR</th>\n",
       "      <th>choiceEV</th>\n",
       "      <th>RPE</th>\n",
       "      <th>totalCPE</th>\n",
       "      <th>decisionCPE</th>\n",
       "      <th>totalRegret</th>\n",
       "      <th>decisionRegret</th>\n",
       "      <th>totalRelief</th>\n",
       "      <th>decisionRelief</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>mix</td>\n",
       "      <td>458.262575</td>\n",
       "      <td>458.273875</td>\n",
       "      <td>462.041225</td>\n",
       "      <td>462.049006</td>\n",
       "      <td>3.767350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>146.0</td>\n",
       "      <td>loss</td>\n",
       "      <td>468.814804</td>\n",
       "      <td>468.828686</td>\n",
       "      <td>473.819151</td>\n",
       "      <td>473.826753</td>\n",
       "      <td>4.990465</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>140.0</td>\n",
       "      <td>loss</td>\n",
       "      <td>480.509956</td>\n",
       "      <td>480.510710</td>\n",
       "      <td>484.830998</td>\n",
       "      <td>484.838941</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>gain</td>\n",
       "      <td>497.135665</td>\n",
       "      <td>497.142355</td>\n",
       "      <td>500.407262</td>\n",
       "      <td>502.416627</td>\n",
       "      <td>3.264907</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>mix</td>\n",
       "      <td>507.397588</td>\n",
       "      <td>507.406724</td>\n",
       "      <td>511.335869</td>\n",
       "      <td>511.343683</td>\n",
       "      <td>3.929145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>127.0</td>\n",
       "      <td>loss</td>\n",
       "      <td>2211.392241</td>\n",
       "      <td>2211.392976</td>\n",
       "      <td>2214.280426</td>\n",
       "      <td>2214.288188</td>\n",
       "      <td>2.887450</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>78.0</td>\n",
       "      <td>gain</td>\n",
       "      <td>2220.904660</td>\n",
       "      <td>2220.905430</td>\n",
       "      <td>2225.208157</td>\n",
       "      <td>2227.218260</td>\n",
       "      <td>4.302726</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>85.0</td>\n",
       "      <td>gain</td>\n",
       "      <td>2236.130865</td>\n",
       "      <td>2236.138261</td>\n",
       "      <td>2238.452797</td>\n",
       "      <td>2240.478945</td>\n",
       "      <td>2.314536</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>148.0</td>\n",
       "      <td>loss</td>\n",
       "      <td>2245.193557</td>\n",
       "      <td>2245.194353</td>\n",
       "      <td>2247.982401</td>\n",
       "      <td>2247.990169</td>\n",
       "      <td>2.788048</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.080</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>137.0</td>\n",
       "      <td>loss</td>\n",
       "      <td>2255.055756</td>\n",
       "      <td>2255.063637</td>\n",
       "      <td>2257.678562</td>\n",
       "      <td>2257.683299</td>\n",
       "      <td>2.614925</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Round  Trial Num TrialType   TrialOnset  ChoiceOnset  DecisionOnset  \\\n",
       "0        1       45.0       mix   458.262575   458.273875     462.041225   \n",
       "1        2      146.0      loss   468.814804   468.828686     473.819151   \n",
       "2        3      140.0      loss   480.509956   480.510710     484.830998   \n",
       "3        4       57.0      gain   497.135665   497.142355     500.407262   \n",
       "4        5       47.0       mix   507.397588   507.406724     511.335869   \n",
       "..     ...        ...       ...          ...          ...            ...   \n",
       "145    146      127.0      loss  2211.392241  2211.392976    2214.280426   \n",
       "146    147       78.0      gain  2220.904660  2220.905430    2225.208157   \n",
       "147    148       85.0      gain  2236.130865  2236.138261    2238.452797   \n",
       "148    149      148.0      loss  2245.193557  2245.194353    2247.982401   \n",
       "149    150      137.0      loss  2255.055756  2255.063637    2257.678562   \n",
       "\n",
       "     FeedbackOnset        RT  SafeBet  LowBet  ...  GambleEV   CR choiceEV  \\\n",
       "0       462.049006  3.767350      0.0   -1.10  ...     0.110  0.0    0.000   \n",
       "1       473.826753  4.990465     -0.6   -1.68  ...    -0.840 -0.6    0.000   \n",
       "2       484.838941  4.320288     -0.5   -2.50  ...    -1.250 -0.5    0.000   \n",
       "3       502.416627  3.264907      0.2    0.00  ...     0.315  0.0    0.315   \n",
       "4       511.343683  3.929145      0.0   -1.10  ...     0.550  0.0    0.000   \n",
       "..             ...       ...      ...     ...  ...       ...  ...      ...   \n",
       "145    2214.288188  2.887450     -0.4   -1.26  ...    -0.630 -0.4    0.000   \n",
       "146    2227.218260  4.302726      0.4    0.00  ...     0.720  0.0    0.720   \n",
       "147    2240.478945  2.314536      0.5    0.00  ...     0.620  0.0    0.620   \n",
       "148    2247.990169  2.788048     -0.6   -2.16  ...    -1.080 -0.6    0.000   \n",
       "149    2257.683299  2.614925     -0.5   -1.58  ...    -0.790 -0.5    0.000   \n",
       "\n",
       "       RPE totalCPE decisionCPE  totalRegret  decisionRegret  totalRelief  \\\n",
       "0    0.000    -1.32       -1.32         0.00             0.0         1.10   \n",
       "1    0.000    -0.60       -0.60        -0.60            -0.6         0.00   \n",
       "2    0.000    -0.50       -0.50         0.00             0.0         2.00   \n",
       "3    0.315     0.00        0.43         0.00             0.0         0.63   \n",
       "4    0.000    -2.20       -2.20         0.00             0.0         1.10   \n",
       "..     ...      ...         ...          ...             ...          ...   \n",
       "145  0.000    -0.40       -0.40        -0.40            -0.4         0.00   \n",
       "146 -0.720    -1.44       -0.40        -1.44            -0.4         0.00   \n",
       "147  0.620     0.00        0.74         0.00             0.0         1.24   \n",
       "148  0.000    -0.60       -0.60         0.00             0.0         1.56   \n",
       "149  0.000    -0.50       -0.50         0.00             0.0         1.08   \n",
       "\n",
       "     decisionRelief  \n",
       "0              1.10  \n",
       "1              0.00  \n",
       "2              2.00  \n",
       "3              0.43  \n",
       "4              1.10  \n",
       "..              ...  \n",
       "145            0.00  \n",
       "146            0.00  \n",
       "147            0.74  \n",
       "148            1.56  \n",
       "149            1.08  \n",
       "\n",
       "[150 rows x 28 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_id = 'DA9'\n",
    "df = pd.read_csv(f'{swb_dir}behavior_analysis/behavior_preprocessed/{subj_id}_task_data')\n",
    "df\n",
    "#risk_est, loss_est, temp_est, bic_est, optim_inits = SWB_modeling_utils.run_base_pt(df,risk_inits,loss_inits,temp_inits,bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12405223957536779\n",
      "0.9140976145081163\n",
      "0.20999593937756938\n",
      "(0.12405223957536779, 0.9140976145081163, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.12405223957536779, 0.9140976145081163, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.12405223957536779, 0.9140976145081163, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.12405223957536779, 0.9140976145081163, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.12405223957536779, 0.9140976145081163, 0.5682189530337132)\n",
      "1.881775558647382\n",
      "0.20999593937756938\n",
      "(0.12405223957536779, 1.881775558647382, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.12405223957536779, 1.881775558647382, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.12405223957536779, 1.881775558647382, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.12405223957536779, 1.881775558647382, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.12405223957536779, 1.881775558647382, 0.5682189530337132)\n",
      "0.22536109947002\n",
      "0.20999593937756938\n",
      "(0.12405223957536779, 0.22536109947002, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.12405223957536779, 0.22536109947002, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.12405223957536779, 0.22536109947002, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.12405223957536779, 0.22536109947002, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.12405223957536779, 0.22536109947002, 0.5682189530337132)\n",
      "1.4262701727304512\n",
      "0.20999593937756938\n",
      "(0.12405223957536779, 1.4262701727304512, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.12405223957536779, 1.4262701727304512, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.12405223957536779, 1.4262701727304512, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.12405223957536779, 1.4262701727304512, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.12405223957536779, 1.4262701727304512, 0.5682189530337132)\n",
      "1.1041183494156956\n",
      "0.20999593937756938\n",
      "(0.12405223957536779, 1.1041183494156956, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.12405223957536779, 1.1041183494156956, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.12405223957536779, 1.1041183494156956, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.12405223957536779, 1.1041183494156956, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.12405223957536779, 1.1041183494156956, 0.5682189530337132)\n",
      "0.20046403774550287\n",
      "0.9140976145081163\n",
      "0.20999593937756938\n",
      "(0.20046403774550287, 0.9140976145081163, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.20046403774550287, 0.9140976145081163, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.20046403774550287, 0.9140976145081163, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.20046403774550287, 0.9140976145081163, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.20046403774550287, 0.9140976145081163, 0.5682189530337132)\n",
      "1.881775558647382\n",
      "0.20999593937756938\n",
      "(0.20046403774550287, 1.881775558647382, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.20046403774550287, 1.881775558647382, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.20046403774550287, 1.881775558647382, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.20046403774550287, 1.881775558647382, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.20046403774550287, 1.881775558647382, 0.5682189530337132)\n",
      "0.22536109947002\n",
      "0.20999593937756938\n",
      "(0.20046403774550287, 0.22536109947002, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.20046403774550287, 0.22536109947002, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.20046403774550287, 0.22536109947002, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.20046403774550287, 0.22536109947002, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.20046403774550287, 0.22536109947002, 0.5682189530337132)\n",
      "1.4262701727304512\n",
      "0.20999593937756938\n",
      "(0.20046403774550287, 1.4262701727304512, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.20046403774550287, 1.4262701727304512, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.20046403774550287, 1.4262701727304512, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.20046403774550287, 1.4262701727304512, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.20046403774550287, 1.4262701727304512, 0.5682189530337132)\n",
      "1.1041183494156956\n",
      "0.20999593937756938\n",
      "(0.20046403774550287, 1.1041183494156956, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.20046403774550287, 1.1041183494156956, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.20046403774550287, 1.1041183494156956, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.20046403774550287, 1.1041183494156956, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.20046403774550287, 1.1041183494156956, 0.5682189530337132)\n",
      "0.4740924247338134\n",
      "0.9140976145081163\n",
      "0.20999593937756938\n",
      "(0.4740924247338134, 0.9140976145081163, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.4740924247338134, 0.9140976145081163, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.4740924247338134, 0.9140976145081163, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.4740924247338134, 0.9140976145081163, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.4740924247338134, 0.9140976145081163, 0.5682189530337132)\n",
      "1.881775558647382\n",
      "0.20999593937756938\n",
      "(0.4740924247338134, 1.881775558647382, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.4740924247338134, 1.881775558647382, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.4740924247338134, 1.881775558647382, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.4740924247338134, 1.881775558647382, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.4740924247338134, 1.881775558647382, 0.5682189530337132)\n",
      "0.22536109947002\n",
      "0.20999593937756938\n",
      "(0.4740924247338134, 0.22536109947002, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.4740924247338134, 0.22536109947002, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.4740924247338134, 0.22536109947002, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.4740924247338134, 0.22536109947002, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.4740924247338134, 0.22536109947002, 0.5682189530337132)\n",
      "1.4262701727304512\n",
      "0.20999593937756938\n",
      "(0.4740924247338134, 1.4262701727304512, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.4740924247338134, 1.4262701727304512, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.4740924247338134, 1.4262701727304512, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.4740924247338134, 1.4262701727304512, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.4740924247338134, 1.4262701727304512, 0.5682189530337132)\n",
      "1.1041183494156956\n",
      "0.20999593937756938\n",
      "(0.4740924247338134, 1.1041183494156956, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.4740924247338134, 1.1041183494156956, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.4740924247338134, 1.1041183494156956, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.4740924247338134, 1.1041183494156956, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.4740924247338134, 1.1041183494156956, 0.5682189530337132)\n",
      "0.11141767160623667\n",
      "0.9140976145081163\n",
      "0.20999593937756938\n",
      "(0.11141767160623667, 0.9140976145081163, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.11141767160623667, 0.9140976145081163, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.11141767160623667, 0.9140976145081163, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.11141767160623667, 0.9140976145081163, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.11141767160623667, 0.9140976145081163, 0.5682189530337132)\n",
      "1.881775558647382\n",
      "0.20999593937756938\n",
      "(0.11141767160623667, 1.881775558647382, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.11141767160623667, 1.881775558647382, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.11141767160623667, 1.881775558647382, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.11141767160623667, 1.881775558647382, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.11141767160623667, 1.881775558647382, 0.5682189530337132)\n",
      "0.22536109947002\n",
      "0.20999593937756938\n",
      "(0.11141767160623667, 0.22536109947002, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.11141767160623667, 0.22536109947002, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.11141767160623667, 0.22536109947002, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.11141767160623667, 0.22536109947002, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.11141767160623667, 0.22536109947002, 0.5682189530337132)\n",
      "1.4262701727304512\n",
      "0.20999593937756938\n",
      "(0.11141767160623667, 1.4262701727304512, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.11141767160623667, 1.4262701727304512, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.11141767160623667, 1.4262701727304512, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.11141767160623667, 1.4262701727304512, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.11141767160623667, 1.4262701727304512, 0.5682189530337132)\n",
      "1.1041183494156956\n",
      "0.20999593937756938\n",
      "(0.11141767160623667, 1.1041183494156956, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.11141767160623667, 1.1041183494156956, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.11141767160623667, 1.1041183494156956, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.11141767160623667, 1.1041183494156956, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.11141767160623667, 1.1041183494156956, 0.5682189530337132)\n",
      "0.2044668829652807\n",
      "0.9140976145081163\n",
      "0.20999593937756938\n",
      "(0.2044668829652807, 0.9140976145081163, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.2044668829652807, 0.9140976145081163, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.2044668829652807, 0.9140976145081163, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.2044668829652807, 0.9140976145081163, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.2044668829652807, 0.9140976145081163, 0.5682189530337132)\n",
      "1.881775558647382\n",
      "0.20999593937756938\n",
      "(0.2044668829652807, 1.881775558647382, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.2044668829652807, 1.881775558647382, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.2044668829652807, 1.881775558647382, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.2044668829652807, 1.881775558647382, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.2044668829652807, 1.881775558647382, 0.5682189530337132)\n",
      "0.22536109947002\n",
      "0.20999593937756938\n",
      "(0.2044668829652807, 0.22536109947002, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.2044668829652807, 0.22536109947002, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.2044668829652807, 0.22536109947002, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.2044668829652807, 0.22536109947002, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.2044668829652807, 0.22536109947002, 0.5682189530337132)\n",
      "1.4262701727304512\n",
      "0.20999593937756938\n",
      "(0.2044668829652807, 1.4262701727304512, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.2044668829652807, 1.4262701727304512, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.2044668829652807, 1.4262701727304512, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.2044668829652807, 1.4262701727304512, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.2044668829652807, 1.4262701727304512, 0.5682189530337132)\n",
      "1.1041183494156956\n",
      "0.20999593937756938\n",
      "(0.2044668829652807, 1.1041183494156956, 0.20999593937756938)\n",
      "1.7491100544100755\n",
      "(0.2044668829652807, 1.1041183494156956, 1.7491100544100755)\n",
      "2.309966165708887\n",
      "(0.2044668829652807, 1.1041183494156956, 2.309966165708887)\n",
      "3.2242484276535492\n",
      "(0.2044668829652807, 1.1041183494156956, 3.2242484276535492)\n",
      "0.5682189530337132\n",
      "(0.2044668829652807, 1.1041183494156956, 0.5682189530337132)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# guess several different starting points for rho\n",
    "for risk_guess in risk_inits:\n",
    "    print(risk_guess)\n",
    "    for loss_guess in loss_inits:\n",
    "        print(loss_guess)\n",
    "        for temp_guess in temp_inits:\n",
    "            print(temp_guess)\n",
    "            init_guess = (risk_guess, loss_guess, temp_guess)\n",
    "\n",
    "            print(init_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12405224 0.20046404 0.47409242 0.11141767 0.20446688] [0.91409761 1.88177556 0.2253611  1.42627017 1.10411835] [0.20999594 1.74911005 2.30996617 3.22424843 0.56821895]\n",
      "0.2044668829652807 1.1041183494156956 0.5682189530337132\n"
     ]
    }
   ],
   "source": [
    "print(risk_inits,loss_inits,temp_inits)\n",
    "print(risk_guess,loss_guess,temp_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2044668829652807, 1.1041183494156956, 0.5682189530337132)\n",
      "0.2044668829652807 1.1041183494156956 0.5682189530337132\n",
      "0.2044668829652807\n",
      "1.1041183494156956\n",
      "0.5682189530337132\n"
     ]
    }
   ],
   "source": [
    "params = init_guess\n",
    "risk_aversion, loss_aversion, inverse_temp = params\n",
    "print(params)\n",
    "print(risk_aversion, loss_aversion, inverse_temp)\n",
    "print(risk_aversion)\n",
    "print(loss_aversion)\n",
    "print(inverse_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_df = (df)\n",
    "\n",
    "res_nll = np.inf\n",
    "res_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds=(0.1,3),(0.1,4),(0.1,20)\n",
    "choiceprob_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_aversion, loss_aversion, inverse_temp = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(subj_df))\n",
    "trial=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round                      1\n",
      "Trial Num               45.0\n",
      "TrialType                mix\n",
      "TrialOnset        458.262575\n",
      "ChoiceOnset       458.273875\n",
      "DecisionOnset     462.041225\n",
      "FeedbackOnset     462.049006\n",
      "RT                   3.76735\n",
      "SafeBet                  0.0\n",
      "LowBet                  -1.1\n",
      "HighBet                 1.32\n",
      "HighBetPos               top\n",
      "GamblePos               left\n",
      "ChoicePos              right\n",
      "GambleChoice            safe\n",
      "Outcome                 good\n",
      "Profit                   0.0\n",
      "TotalProfit             10.0\n",
      "GambleEV                0.11\n",
      "CR                       0.0\n",
      "choiceEV                 0.0\n",
      "RPE                      0.0\n",
      "totalCPE               -1.32\n",
      "decisionCPE            -1.32\n",
      "totalRegret              0.0\n",
      "decisionRegret           0.0\n",
      "totalRelief              1.1\n",
      "decisionRelief           1.1\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "    trial_info = subj_df.iloc[trial]\n",
    "    high_bet = trial_info['HighBet']\n",
    "    low_bet = trial_info['LowBet']\n",
    "    safe_bet = trial_info['SafeBet']\n",
    "    trial_type = trial_info['TrialType']\n",
    "    choice = trial_info['GambleChoice']\n",
    "    print(trial_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.32\n",
      "-1.1\n",
      "0.0\n",
      "mix\n",
      "safe\n"
     ]
    }
   ],
   "source": [
    "print(high_bet)\n",
    "print(low_bet)\n",
    "print(safe_bet)\n",
    "print(trial_type)\n",
    "print(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to high bet value to utility (gamble)\n",
    "if high_bet > 0: #mix or gain trials\n",
    "    weighted_high_bet = 0.5 * ((high_bet)**risk_aversion)\n",
    "else: #loss trials\n",
    "    weighted_high_bet = 0 \n",
    "\n",
    "# transform to low bet value to utility (gamble)\n",
    "if low_bet < 0: #loss and mix trials\n",
    "    weighted_low_bet = -0.5 * loss_aversion * ((-low_bet)**risk_aversion)\n",
    "    \n",
    "else: #gain trials\n",
    "    weighted_low_bet = 0 \n",
    "\n",
    "util_gamble = weighted_high_bet + weighted_low_bet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2044668829652807"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_aversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5292043193352624"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_high_bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5629230928825413"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_low_bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.033718773547278924"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util_gamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform safe bet value to utility (safe)\n",
    "if safe_bet >= 0: #gain or mix trials\n",
    "    util_safe = (safe_bet)**risk_aversion\n",
    "else: #loss trials\n",
    "    util_safe = -loss_aversion * ((-safe_bet)**risk_aversion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(util_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert EV to choice probabilities via softmax\n",
    "p_gamble = np.exp(inverse_temp*util_gamble) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "p_safe = np.exp(inverse_temp*util_safe) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49521023497216865 0.5047897650278315\n"
     ]
    }
   ],
   "source": [
    "print(p_gamble,p_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safe'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append probability of chosen options\n",
    "if choice == 'gamble':\n",
    "    choiceprob_list.append(p_gamble)\n",
    "elif choice == 'safe':\n",
    "    choiceprob_list.append(p_safe)\n",
    "else:\n",
    "    choiceprob_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5047897650278315]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choiceprob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6836132432621236\n"
     ]
    }
   ],
   "source": [
    "negLL = -np.sum(np.log(choiceprob_list))\n",
    "print(negLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negLL < res_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_nll = negLL\n",
    "param_fits = \n",
    "risk_aversion, loss_aversion, inverse_temp = param_fits\n",
    "optim_vars = init_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.1, 3), (0.1, 4), (0.1, 20))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "[0.20446688 1.10411835 0.56821895]\n"
     ]
    }
   ],
   "source": [
    "# params = init_guess\n",
    "# risk_aversion, loss_aversion, inverse_temp = params\n",
    "# print(params)\n",
    "init_list = [risk_aversion,loss_aversion,inverse_temp]\n",
    "init_np = np.array([risk_aversion,loss_aversion,inverse_temp])\n",
    "print(type(params))\n",
    "print(type(init_guess))\n",
    "print(type(init_list))\n",
    "print(type(init_np))\n",
    "print(init_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = minimize(negll_base_pt, \n",
    "                x0=init_guess, \n",
    "                args=subj_df, \n",
    "                method='L-BFGS-B',\n",
    "                bounds=bounds) #should match bounds given to param_init \n",
    "\n",
    "# if current negLL is smaller than the last negLL,\n",
    "# # then store current data\n",
    "# if result.fun < res_nll:\n",
    "#     res_nll = result.fun\n",
    "#     param_fits = result.x\n",
    "#     risk_aversion, loss_aversion, inverse_temp = param_fits\n",
    "#     optim_vars = init_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = minimize(negll_base_pt, \n",
    "                x0=init_list, \n",
    "                args=subj_df, \n",
    "                method='L-BFGS-B',\n",
    "                bounds=bounds) #should match bounds given to param_init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20446688, 1.10411835, 0.56821895])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_np = minimize(negll_base_pt, \n",
    "                x0=init_np, \n",
    "                args=subj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20446688, 1.10411835, 0.56821895])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_np.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2044668829652807, 1.1041183494156956, 0.5682189530337132)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20446688, 1.10411835, 0.56821895])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.fun < res_nll:\n",
    "    res_nll = result.fun\n",
    "    param_fits = result.x\n",
    "    risk_aversion, loss_aversion, inverse_temp = param_fits\n",
    "    optim_vars = init_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negll_base_pt(params,subj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_aversion, loss_aversion, inverse_temp = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init list of choice prob predictions\n",
    "choiceprob_list = []\n",
    "\n",
    "#loop through trials\n",
    "for trial in range(len(subj_df)):\n",
    "\n",
    "    # get relevant trial info\n",
    "    trial_info = subj_df.iloc[trial]\n",
    "    high_bet = trial_info['HighBet']\n",
    "    low_bet = trial_info['LowBet']\n",
    "    safe_bet = trial_info['SafeBet']\n",
    "    trial_type = trial_info['TrialType']\n",
    "    choice = trial_info['GambleChoice']\n",
    "\n",
    "    \n",
    "    #for simulation df - should change simulation code to match behavior data\n",
    "    # trial_info = subj_df.iloc[trial]\n",
    "    # high_bet = trial_info['high_bet']\n",
    "    # low_bet = trial_info['low_bet']\n",
    "    # safe_bet = trial_info['safe_bet']\n",
    "    # trial_type = trial_info['type']\n",
    "    # choice = trial_info['choice_pred']\n",
    "\n",
    "    # transform to high bet value to utility (gamble)\n",
    "    if high_bet > 0: #mix or gain trials\n",
    "        weighted_high_bet = 0.5 * ((high_bet)**risk_aversion)\n",
    "    else: #loss trials\n",
    "        weighted_high_bet = 0 \n",
    "    \n",
    "    # transform to low bet value to utility (gamble)\n",
    "    if low_bet < 0: #loss and mix trials\n",
    "        weighted_low_bet = -0.5 * loss_aversion * ((-low_bet)**risk_aversion)\n",
    "        \n",
    "    else: #gain trials\n",
    "        weighted_low_bet = 0 \n",
    "    \n",
    "    util_gamble = weighted_high_bet + weighted_low_bet\n",
    "\n",
    "\n",
    "    # transform safe bet value to utility (safe)\n",
    "    if safe_bet >= 0: #gain or mix trials\n",
    "        util_safe = (safe_bet)**risk_aversion\n",
    "    else: #loss trials\n",
    "        util_safe = -loss_aversion * ((-safe_bet)**risk_aversion)\n",
    "\n",
    "\n",
    "\n",
    "    # convert EV to choice probabilities via softmax\n",
    "    p_gamble = np.exp(inverse_temp*util_gamble) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "    p_safe = np.exp(inverse_temp*util_safe) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "\n",
    "    # if np.isnan(p_gamble): #when utility is too large, probabilities cannot be estimated \n",
    "    #     p_gamble = 0.99\n",
    "    #     p_safe = 0.01\n",
    "    # if np.isnan(p_safe):\n",
    "    #     p_safe = 0.99\n",
    "    #     p_gamble = 0.01\n",
    "    \n",
    "\n",
    "    # append probability of chosen options\n",
    "    if choice == 'gamble':\n",
    "        choiceprob_list.append(p_gamble)\n",
    "    elif choice == 'safe':\n",
    "        choiceprob_list.append(p_safe)\n",
    "    else:\n",
    "        choiceprob_list.append(0)\n",
    "\n",
    "# compute the neg LL of choice probabilities across the entire task\n",
    "negLL = -np.sum(np.log(choiceprob_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def negll_base_pt(params, subj_df):\n",
    "    risk_aversion, loss_aversion, inverse_temp = params\n",
    "    #if using log transform then \n",
    "\n",
    "    # init list of choice prob predictions\n",
    "    choiceprob_list = []\n",
    "\n",
    "    #loop through trials\n",
    "    for trial in range(len(subj_df)):\n",
    "\n",
    "        # get relevant trial info\n",
    "        trial_info = subj_df.iloc[trial]\n",
    "        high_bet = trial_info['HighBet']\n",
    "        low_bet = trial_info['LowBet']\n",
    "        safe_bet = trial_info['SafeBet']\n",
    "        trial_type = trial_info['TrialType']\n",
    "        choice = trial_info['GambleChoice']\n",
    "\n",
    "        \n",
    "        #for simulation df - should change simulation code to match behavior data\n",
    "        # trial_info = subj_df.iloc[trial]\n",
    "        # high_bet = trial_info['high_bet']\n",
    "        # low_bet = trial_info['low_bet']\n",
    "        # safe_bet = trial_info['safe_bet']\n",
    "        # trial_type = trial_info['type']\n",
    "        # choice = trial_info['choice_pred']\n",
    "\n",
    "        # transform to high bet value to utility (gamble)\n",
    "        if high_bet > 0: #mix or gain trials\n",
    "            weighted_high_bet = 0.5 * ((high_bet)**risk_aversion)\n",
    "        else: #loss trials\n",
    "            weighted_high_bet = 0 \n",
    "        \n",
    "        # transform to low bet value to utility (gamble)\n",
    "        if low_bet < 0: #loss and mix trials\n",
    "            weighted_low_bet = -0.5 * loss_aversion * ((-low_bet)**risk_aversion)\n",
    "            \n",
    "        else: #gain trials\n",
    "            weighted_low_bet = 0 \n",
    "        \n",
    "        util_gamble = weighted_high_bet + weighted_low_bet\n",
    "    \n",
    "\n",
    "        # transform safe bet value to utility (safe)\n",
    "        if safe_bet >= 0: #gain or mix trials\n",
    "            util_safe = (safe_bet)**risk_aversion\n",
    "        else: #loss trials\n",
    "            util_safe = -loss_aversion * ((-safe_bet)**risk_aversion)\n",
    "\n",
    "\n",
    "\n",
    "        # convert EV to choice probabilities via softmax\n",
    "        p_gamble = np.exp(inverse_temp*util_gamble) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "        p_safe = np.exp(inverse_temp*util_safe) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "\n",
    "        # if np.isnan(p_gamble): #when utility is too large, probabilities cannot be estimated \n",
    "        #     p_gamble = 0.99\n",
    "        #     p_safe = 0.01\n",
    "        # if np.isnan(p_safe):\n",
    "        #     p_safe = 0.99\n",
    "        #     p_gamble = 0.01\n",
    "        \n",
    "\n",
    "        # append probability of chosen options\n",
    "        if choice == 'gamble':\n",
    "            choiceprob_list.append(p_gamble)\n",
    "        elif choice == 'safe':\n",
    "            choiceprob_list.append(p_safe)\n",
    "        else:\n",
    "            choiceprob_list.append(0)\n",
    "\n",
    "    # compute the neg LL of choice probabilities across the entire task\n",
    "    negLL = -np.sum(np.log(choiceprob_list))\n",
    "    \n",
    "    if np.isnan(negLL):\n",
    "        return np.inf\n",
    "    else:\n",
    "        return negLL, \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5047897650278315, 0.4461189184123311, 0.45855734439463186, 0.4624743890931515, 0.49651335779128386, 0.4955121585106131, 0.521205505484407, 0.4459708094926683, 0.45093300179202184, 0.5517883503075384, 0.5124763314230155, 0.5396022220547553, 0.46265137160254455, 0.48980203179099924, 0.5424145296264146, 0.5414156621880039, 0.4612684962772367, 0.5233279127969109, 0.4986356446894883, 0.5432201977787249, 0.4634729107747212, 0.4858710696659018, 0.5248527615158303, 0.49901822541067964, 0.44839738829062575, 0.45020081524955663, 0.48663814077875134, 0.5236854021407569, 0.49218720659373816, 0.4593198704496165, 0.4781407096921947, 0.5469349406722395, 0.5199039036949407, 0.45699089165069706, 0.4935823136649471, 0.5487244265042407, 0.5029675307325341, 0.4888988487841418, 0.4529420378981364, 0.45037631177082066, 0.4596854979756086, 0.4847363626468501, 0.49245978879205865, 0.4919662103490439, 0.5096815644786981, 0.46636987901586474, 0.43761931160137096, 0.45230584677342545, 0.5104507612714336, 0.498800202339311, 0.4479332736427809, 0.44455285704990455, 0.4569213242527171, 0.45194698671575245, 0.4594681746590785, 0.4959233467596523, 0.5032668554712151, 0.4963276432508213, 0.45950976976862173, 0.4403963135990058, 0.45510605065585047, 0.4821091477255197, 0.4609456637276033, 0.46561306995961266, 0.4628806395418431, 0.48856322285722087, 0.4813496081387217, 0.4605463946512956, 0.4434489060986029, 0.4480760828083571, 0.47866064371522965, 0.5574422490218326, 0.46425351909845547, 0.45793582460194077, 0.44751996025101154, 0.444227446212299, 0.4552695591655111, 0.4558451181141751, 0.44565570711236596, 0.4610293501325386, 0.5468060313723712, 0.4567873365953692, 0.5446845810406944, 0.44831605692107324, 0.49421874319823894, 0.44697960963823413, 0.4989101358177409, 0.43984925615212805, 0.4478484041032735, 0.4424642683926383, 0.4454740542450191, 0.4517208204098875, 0.454870003958709, 0, 0.5176847618448654, 0.46411876533920066, 0.5026732246942646, 0.4524618485420644, 0.44944902061905156, 0.45529367279720867, 0.45023974270734896, 0.46117561608748125, 0.4460402273651551, 0.4388348465176513, 0.45116584937328735, 0.4437260175081717, 0.4948966681498734, 0.48456293225285735, 0.4507454311114592, 0.4421024990695881, 0.4535801955398298, 0.5143158189135933, 0.45553431537514943, 0.4624499108971008, 0.5589197360897877, 0.45323360751459857, 0.5166442142939248, 0.4498069267118764, 0.5169428870669573, 0.47392960113158705, 0.4465918371668991, 0.4545126151821054, 0.4550292347853161, 0.45457010271429066, 0.4535741177058651, 0.46884692166855335, 0.4489938461485069, 0.44927037807233894, 0.4440306478081832, 0.519858602614093, 0.4571521722101114, 0.4450985687068303, 0.457254587644675, 0.45483095638924464, 0.5278209036798915, 0.49871948044067255, 0.5088682586621937, 0.4703617886542185, 0.46616202358385694, 0.45793031134664275, 0.4467304038314552, 0.49628509400097814, 0.4531598037850113, 0.49293504809776817, 0.4568986153319136, 0.452314151979957, 0.45883374807147315, 0.45109442914956377, 0.45066776745273435, 0.45015777924451844]\n"
     ]
    }
   ],
   "source": [
    "print(choiceprob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#log transform for input to optim - then untransform in negll eq \n",
    "\n",
    "# guesses for alpha, theta will change on each loop\n",
    "\n",
    "# minimize neg LL\n",
    "# result = minimize(negll_base_pt, \n",
    "#                 x0=init_guess, \n",
    "#                 args=subj_df, \n",
    "#                 method='L-BFGS-B',\n",
    "#                 bounds=bounds) #should match bounds given to param_init \n",
    "\n",
    "# if current negLL is smaller than the last negLL,\n",
    "# then store current data\n",
    "if result.fun < res_nll:\n",
    "    res_nll = result.fun\n",
    "    param_fits = result.x\n",
    "    risk_aversion, loss_aversion, inverse_temp = param_fits\n",
    "    optim_vars = init_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loop through trials\n",
    "for trial in range(len(subj_df)):\n",
    "\n",
    "    # get relevant trial info\n",
    "    trial_info = subj_df.iloc[trial]\n",
    "    high_bet = trial_info['HighBet']\n",
    "    low_bet = trial_info['LowBet']\n",
    "    safe_bet = trial_info['SafeBet']\n",
    "    trial_type = trial_info['TrialType']\n",
    "    choice = trial_info['GambleChoice']\n",
    "\n",
    "    \n",
    "    #for simulation df - should change simulation code to match behavior data\n",
    "    # trial_info = subj_df.iloc[trial]\n",
    "    # high_bet = trial_info['high_bet']\n",
    "    # low_bet = trial_info['low_bet']\n",
    "    # safe_bet = trial_info['safe_bet']\n",
    "    # trial_type = trial_info['type']\n",
    "    # choice = trial_info['choice_pred']\n",
    "\n",
    "    # transform to high bet value to utility (gamble)\n",
    "    if high_bet > 0: #mix or gain trials\n",
    "        weighted_high_bet = 0.5 * ((high_bet)**risk_aversion)\n",
    "    else: #loss trials\n",
    "        weighted_high_bet = 0 \n",
    "    \n",
    "    # transform to low bet value to utility (gamble)\n",
    "    if low_bet < 0: #loss and mix trials\n",
    "        weighted_low_bet = -0.5 * loss_aversion * ((-low_bet)**risk_aversion)\n",
    "        \n",
    "    else: #gain trials\n",
    "        weighted_low_bet = 0 \n",
    "    \n",
    "    util_gamble = weighted_high_bet + weighted_low_bet\n",
    "\n",
    "\n",
    "    # transform safe bet value to utility (safe)\n",
    "    if safe_bet >= 0: #gain or mix trials\n",
    "        util_safe = (safe_bet)**risk_aversion\n",
    "    else: #loss trials\n",
    "        util_safe = -loss_aversion * ((-safe_bet)**risk_aversion)\n",
    "\n",
    "\n",
    "\n",
    "    # convert EV to choice probabilities via softmax\n",
    "    p_gamble = np.exp(inverse_temp*util_gamble) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "    p_safe = np.exp(inverse_temp*util_safe) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "\n",
    "    # if np.isnan(p_gamble): #when utility is too large, probabilities cannot be estimated \n",
    "    #     p_gamble = 0.99\n",
    "    #     p_safe = 0.01\n",
    "    # if np.isnan(p_safe):\n",
    "    #     p_safe = 0.99\n",
    "    #     p_gamble = 0.01\n",
    "    \n",
    "\n",
    "    # append probability of chosen options\n",
    "    if choice == 'gamble':\n",
    "        choiceprob_list.append(p_gamble)\n",
    "    elif choice == 'safe':\n",
    "        choiceprob_list.append(p_safe)\n",
    "    else:\n",
    "        choiceprob_list.append(0)\n",
    "\n",
    "# compute the neg LL of choice probabilities across the entire task\n",
    "negLL = -np.sum(np.log(choiceprob_list))\n",
    "print(negLL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "if res_nll == np.inf:\n",
    "    print('No solution for this patient')\n",
    "    risk_aversion=0\n",
    "    loss_aversion=0\n",
    "    inverse_temp=0\n",
    "    BIC=0\n",
    "    optim_vars=0\n",
    "    #return risk_aversion, loss_aversion, inverse_temp, BIC, optim_vars\n",
    "else:\n",
    "    BIC = len(init_guess) * np.log(len(subj_df)) + 2*res_nll\n",
    "print(risk_aversion,loss_aversion,inverse_temp,BIC,optim_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_aversion, loss_aversion, inverse_temp = params\n",
    "#if using log transform then \n",
    "\n",
    "# init list of choice prob predictions\n",
    "choiceprob_list = []\n",
    "\n",
    "#loop through trials\n",
    "for trial in range(len(subj_df)):\n",
    "\n",
    "    # get relevant trial info\n",
    "    trial_info = subj_df.iloc[trial]\n",
    "    high_bet = trial_info['HighBet']\n",
    "    low_bet = trial_info['LowBet']\n",
    "    safe_bet = trial_info['SafeBet']\n",
    "    trial_type = trial_info['TrialType']\n",
    "    choice = trial_info['GambleChoice']\n",
    "\n",
    "    \n",
    "    #for simulation df - should change simulation code to match behavior data\n",
    "    # trial_info = subj_df.iloc[trial]\n",
    "    # high_bet = trial_info['high_bet']\n",
    "    # low_bet = trial_info['low_bet']\n",
    "    # safe_bet = trial_info['safe_bet']\n",
    "    # trial_type = trial_info['type']\n",
    "    # choice = trial_info['choice_pred']\n",
    "\n",
    "    # transform to high bet value to utility (gamble)\n",
    "    if high_bet > 0: #mix or gain trials\n",
    "        weighted_high_bet = 0.5 * ((high_bet)**risk_aversion)\n",
    "    else: #loss trials\n",
    "        weighted_high_bet = 0 \n",
    "    \n",
    "    # transform to low bet value to utility (gamble)\n",
    "    if low_bet < 0: #loss and mix trials\n",
    "        weighted_low_bet = -0.5 * loss_aversion * ((-low_bet)**risk_aversion)\n",
    "        \n",
    "    else: #gain trials\n",
    "        weighted_low_bet = 0 \n",
    "    \n",
    "    util_gamble = weighted_high_bet + weighted_low_bet\n",
    "\n",
    "\n",
    "    # transform safe bet value to utility (safe)\n",
    "    if safe_bet >= 0: #gain or mix trials\n",
    "        util_safe = (safe_bet)**risk_aversion\n",
    "    else: #loss trials\n",
    "        util_safe = -loss_aversion * ((-safe_bet)**risk_aversion)\n",
    "\n",
    "\n",
    "\n",
    "    # convert EV to choice probabilities via softmax\n",
    "    p_gamble = np.exp(inverse_temp*util_gamble) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "    p_safe = np.exp(inverse_temp*util_safe) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "\n",
    "    if np.isnan(p_gamble): #when utility is too large, probabilities cannot be estimated \n",
    "        p_gamble = 0.99\n",
    "        p_safe = 0.01\n",
    "    if np.isnan(p_safe):\n",
    "        p_safe = 0.99\n",
    "        p_gamble = 0.01\n",
    "    \n",
    "\n",
    "    # append probability of chosen options\n",
    "    if choice == 'gamble':\n",
    "        choiceprob_list.append(p_gamble)\n",
    "    elif choice == 'safe':\n",
    "        choiceprob_list.append(p_safe)\n",
    "    else:\n",
    "        choiceprob_list.append(0)\n",
    "\n",
    "# compute the neg LL of choice probabilities across the entire task\n",
    "negLL = -np.sum(np.log(choiceprob_list))\n",
    "print(negLL)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pt models with optim params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = pd.read_excel('/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/SWB_subjects.xlsx', sheet_name=0,usecols='A')\n",
    "behav_path = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/behavior_analysis/behavior_preprocessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update model data for GLM inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_path = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/SWB/swb_computational_modeling/swb_behav_models/data/model_input_data_06192023'\n",
    "model_input = pd.read_csv(model_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
