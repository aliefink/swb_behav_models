{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tversky, A., & Kahneman, D. (1992). Advances in prospect theory: Cumulative representation of uncertainty. Journal of Risk and uncertainty, 5, 297-323. https://link.springer.com/article/10.1007/BF00122574\n",
    "# Charpentier, C. J., Aylward, J., Roiser, J. P., & Robinson, O. J. (2017). Enhanced risk aversion, but not loss aversion, in unmedicated pathological anxiety. Biological psychiatry, 81(12), 1014-1022. https://www.sciencedirect.com/science/article/pii/S0006322316331110?via%3Dihub#bib28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df = pd.read_csv('example_data\\\\MS017_task_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negll_prospect3(params, subj_df):\n",
    "    risk_aversion, loss_aversion, inverse_temp = params\n",
    "\n",
    "    # init list of choice prob predictions\n",
    "    choiceprob_list = []\n",
    "\n",
    "\n",
    "    #loop through trials\n",
    "    for trial in range(len(subj_df)):\n",
    "\n",
    "        # get relevant trial info\n",
    "        trial_info = subj_df.iloc[trial]\n",
    "        high_bet = trial_info['High.Bet']\n",
    "        low_bet = trial_info['Low.Bet']\n",
    "        safe_bet = trial_info['Safe.Bet']\n",
    "        trial_type = trial_info['TrialType']\n",
    "        choice = trial_info['Gamble.Choice']\n",
    "        outcome = trial_info['Profit']\n",
    "\n",
    "        # transform to high bet value to utility (gamble)\n",
    "        if high_bet >= 0:\n",
    "            weighted_high_bet = 0.5 * (high_bet)**risk_aversion\n",
    "        else:\n",
    "            weighted_high_bet = -0.5 * loss_aversion * (-high_bet)**risk_aversion\n",
    "        \n",
    "        # transform to low bet value to utility (gamble)\n",
    "        if low_bet >= 0:\n",
    "            weighted_low_bet = 0.5 * (low_bet)**risk_aversion\n",
    "        else:\n",
    "            weighted_low_bet = -0.5 * loss_aversion * (-low_bet)**risk_aversion\n",
    "        \n",
    "        util_gamble = weighted_high_bet + weighted_low_bet\n",
    "\n",
    "        # transform safe bet value to utility (safe)\n",
    "        if safe_bet >= 0:\n",
    "            util_safe = (safe_bet)**risk_aversion\n",
    "        else:\n",
    "            util_safe = -loss_aversion * (-safe_bet)**risk_aversion\n",
    "\n",
    "        #print(f'{trial_type}: U(gamble) = {util_gamble:.3f}; U(safe) = {util_safe:.3f}')\n",
    "\n",
    "        # convert EV to choice probabilities via softmax\n",
    "        p_gamble = np.exp(inverse_temp*util_gamble) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "        p_safe = np.exp(inverse_temp*util_safe) / ( np.exp(inverse_temp*util_gamble) + np.exp(inverse_temp*util_safe) )\n",
    "        \n",
    "        #print(f'{trial_type}: P(gamble) = {p_gamble:.3f}', f'P(safe) = {p_safe:.3f}')\n",
    "\n",
    "        # append probability of chosen options\n",
    "        if choice == 'gamble':\n",
    "            choiceprob_list.append(p_gamble)\n",
    "        elif choice == 'safe':\n",
    "            choiceprob_list.append(p_safe)\n",
    "\n",
    "    # compute the neg LL of choice probabilities across the entire task\n",
    "    negLL = -np.sum(np.log(choiceprob_list))\n",
    "    \n",
    "    if np.isnan(negLL):\n",
    "        return np.inf\n",
    "    else:\n",
    "        return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: overflow encountered in exp\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:43: RuntimeWarning: overflow encountered in exp\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      " 25%|██▌       | 1/4 [00:40<02:01, 40.36s/it]c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:54: RuntimeWarning: divide by zero encountered in log\n",
      "100%|██████████| 4/4 [01:42<00:00, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_aversion = 1.3260, loss_aversion = 0.9892, inverse_temp = 6.3368\n",
      "BIC = 148.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# gradient descent to minimize neg LL\n",
    "res_nll = np.inf # set initial neg LL to be inf\n",
    "\n",
    "# rho    = risk_aversion_\n",
    "# lambda = loss_aversion\n",
    "# beta   = inverse_temp\n",
    "\n",
    "# guess several different starting points for rho\n",
    "for rho_guess in tqdm(np.linspace(0,6,4)):\n",
    "        for lambda_guess in np.linspace(0,20,4):\n",
    "            for beta_guess in np.linspace(1,20,4):\n",
    "        \n",
    "                # guesses for alpha, theta will change on each loop\n",
    "                init_guess = (rho_guess, lambda_guess, beta_guess)\n",
    "                \n",
    "                # minimize neg LL\n",
    "                result = minimize(negll_prospect3, \n",
    "                                 init_guess, \n",
    "                                 (subj_df), \n",
    "                                 bounds=((0,6),(0,50),(.001,50)))\n",
    "                \n",
    "                # if current negLL is smaller than the last negLL,\n",
    "                # then store current data\n",
    "                if result.fun < res_nll:\n",
    "                    res_nll = result.fun\n",
    "                    param_fits = result.x\n",
    "                    risk_aversion, loss_aversion, inverse_temp = param_fits\n",
    "\n",
    "# also, compute BIC\n",
    "# note: we don't need the -1 because \n",
    "# we already have the negative log likelihood!\n",
    "BIC = len(init_guess) * np.log(len(subj_df)) + 2*res_nll\n",
    "\n",
    "print(fr'risk_aversion = {risk_aversion:.4f}, loss_aversion = {loss_aversion:.4f}, inverse_temp = {inverse_temp:.4f}')\n",
    "print(fr'BIC = {BIC:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negll_prospect4(params, subj_df):\n",
    "    risk_aversion_pos, risk_aversion_neg, loss_aversion, inverse_temp = params\n",
    "\n",
    "    # init list of choice prob predictions\n",
    "    choiceprob_list = []\n",
    "\n",
    "    #loop through trials\n",
    "    for trial in range(len(subj_df)):\n",
    "\n",
    "        # get relevant trial info\n",
    "        trial_info = subj_df.iloc[trial]\n",
    "        high_bet = trial_info['High.Bet']\n",
    "        low_bet = trial_info['Low.Bet']\n",
    "        safe_bet = trial_info['Safe.Bet']\n",
    "        trial_type = trial_info['TrialType']\n",
    "        choice = trial_info['Gamble.Choice']\n",
    "        outcome = trial_info['Profit']\n",
    "\n",
    "        # transform to high bet value to utility (gamble)\n",
    "        if high_bet >= 0:\n",
    "            weighted_high_bet = 0.5 * (high_bet)**risk_aversion_pos\n",
    "        else:\n",
    "            weighted_high_bet = -0.5 * loss_aversion * (-high_bet)**risk_aversion_neg\n",
    "        \n",
    "        # transform to low bet value to utility (gamble)\n",
    "        if low_bet >= 0:\n",
    "            weighted_low_bet = 0.5 * (low_bet)**risk_aversion_pos\n",
    "        else:\n",
    "            weighted_low_bet = -0.5 * loss_aversion * (-low_bet)**risk_aversion_neg\n",
    "        \n",
    "        util_gamble = weighted_high_bet + weighted_low_bet\n",
    "\n",
    "        # transform safe bet value to utility (safe)\n",
    "        if safe_bet >= 0:\n",
    "            util_safe = (safe_bet)**risk_aversion_pos\n",
    "        else:\n",
    "            util_safe = -loss_aversion * (-safe_bet)**risk_aversion_neg\n",
    "\n",
    "        # convert EV to choice probabilities via softmax\n",
    "        p_gamble = np.exp(inverse_temp*util_gamble) / ( np.exp(inverse_temp*util_gamble) +  np.exp(inverse_temp*util_safe) )\n",
    "        p_safe = np.exp(inverse_temp*util_safe) / ( np.exp(inverse_temp*util_gamble) +  np.exp(inverse_temp*util_safe) )\n",
    "        \n",
    "        #print(trial_type, f'{p_gamble:.3f}', f'{p_safe:.3f}')\n",
    "\n",
    "        # append probability of chosen options\n",
    "        if choice == 'gamble':\n",
    "            choiceprob_list.append(p_gamble)\n",
    "        elif choice == 'safe':\n",
    "            choiceprob_list.append(p_safe)\n",
    "\n",
    "    # compute the neg LL of choice probabilities across the entire task\n",
    "    negLL = -np.sum(np.log(choiceprob_list))\n",
    "\n",
    "    return negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: overflow encountered in exp\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:41: RuntimeWarning: overflow encountered in exp\n",
      "c:\\ProgramData\\Anaconda3\\envs\\ccp\\lib\\site-packages\\ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in log\n",
      "100%|██████████| 4/4 [11:31<00:00, 172.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_aversion_pos = 1.0509, risk_aversion_neg = 1.4683, loss_aversion = 0.8937, inverse_temp = 8.1392\n",
      "BIC = 149.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# gradient descent to minimize neg LL\n",
    "res_nll = np.inf # set initial neg LL to be inf\n",
    "\n",
    "# rho_pos = risk_aversion_pos\n",
    "# rho_neg = risk_aversion_neg\n",
    "# lambda  = loss_aversion\n",
    "# beta    = inverse_temp\n",
    "\n",
    "# guess several different starting points\n",
    "for rho_pos_guess in tqdm(np.linspace(0,6,4)):\n",
    "    for rho_neg_guess in np.linspace(0,6,4):\n",
    "        for lambda_guess in np.linspace(0,20,4):\n",
    "            for beta_guess in np.linspace(1,20,4):\n",
    "        \n",
    "                # guesses for alpha, theta will change on each loop\n",
    "                init_guess = (rho_pos_guess, rho_neg_guess, lambda_guess, beta_guess)\n",
    "                \n",
    "                # minimize neg LL\n",
    "                result = minimize(negll_prospect4, \n",
    "                                 init_guess, \n",
    "                                 (subj_df), \n",
    "                                 bounds=((0,6),(0,6),(0,50),(.001,50)))\n",
    "                \n",
    "                # if current negLL is smaller than the last negLL,\n",
    "                # then store current data\n",
    "                if result.fun < res_nll:\n",
    "                    res_nll = result.fun\n",
    "                    param_fits = result.x\n",
    "                    risk_aversion_pos, risk_aversion_neg, loss_aversion, inverse_temp = param_fits\n",
    "\n",
    "# also, compute BIC\n",
    "# note: we don't need the -1 because \n",
    "# we already have the negative log likelihood!\n",
    "BIC = len(init_guess) * np.log(len(subj_df)) + 2*res_nll\n",
    "\n",
    "print(fr'risk_aversion_pos = {risk_aversion_pos:.4f}, risk_aversion_neg = {risk_aversion_neg:.4f}, loss_aversion = {loss_aversion:.4f}, inverse_temp = {inverse_temp:.4f}')\n",
    "print(fr'BIC = {BIC:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swb_computational_modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d44df5d2e961877584286d11e54e0f62dbc0de85878c8cdf3b51452b1ce7d435"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
